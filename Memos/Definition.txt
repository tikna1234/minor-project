##Features of Python#3
Easy to Code
Free and open source
GUI support
High level language
Large Standard Liraries
Object Oriented Programming lanugage
Platform Independent

##Machine learning##

Machine Learning is a branch of artificial intelligence that develops algorithms by learning the hidden patterns of the datasets used it to make predictions on new similar type data, without being explicitly programmed for each task.

Machine learning is used in many different applications, from image and speech recognition to natural language processing, recommendation systems, fraud detection, portfolio optimization, automated task, and so on. Machine learning models are also used to power autonomous vehicles, drones, and robots, making them more intelligent and adaptable to changing environments.

A typical machine learning tasks are to provide a recommendation. Recommender systems are a common application of machine learning, and they use historical data to provide personalized recommendations to users.

Types of Machine Learning
1. Supervised Machine Learning
2. Unsupervised Machine Learning
3. Reinforcement Machine Learning

##Supervised learning##

Supervised learning is a type of machine learning in which the algorithm is trained on the labeled dataset. It learns to map input features to targets based on labeled training data. In supervised learning, the algorithm is provided with input features and corresponding output labels, and it learns to generalize from this data to make predictions on new, unseen data.
There are two main types of supervised learning:
1. Regression
2. Classification

##Unsupervised Machine Learning##

Unsupervised Learning Unsupervised learning is a type of machine learning technique in which an algorithm discovers patterns and relationships using unlabeled data.The primary goal of Unsupervised learning is often to discover hidden patterns, similarities, or clusters within the data, which can then be used for various purposes, such as data exploration, visualization, dimensionality reduction, and more.

##Reinforcement Machine learning
Reinforcement Learning (RL) is a type of machine learning paradigm where an agent learns to make decisions by interacting with an environment.In this technique, the model keeps on increasing its performance using Reward Feedback to learn the behavior or pattern. These algorithms are specific to a particular problem e.g. Google Self Driving car, AlphaGo where a bot competes with humans and even itself to get better and better performers in Go Game. Each time we feed in data, they learn and add the data to their knowledge which is training data. So, the more it learns the better it gets trained and hence experienced. 

##Classification##

Classification is a type of supervised learning where the algorithm learns to assign input data to a specific category or class based on input features. The output labels in classification are discrete values. Classification algorithms can be binary, where the output is one of two possible classes, or multiclass, where the output can be one of several classes. The different Classification algorithms in machine learning are: Logistic Regression, Naive Bayes, Decision Tree, Support Vector Machine (SVM), K-Nearest Neighbors (KNN), etc

##Content based filtering##


Content-based filtering is a machine learning approach used in recommendation systems to suggest items to users based on the characteristics of the items and the preferences of the users. Instead of relying on the collaborative behavior of users (as seen in collaborative filtering), content-based filtering considers the features or attributes of items and recommends new items that are similar to those a user has liked or interacted with in the past.
In machine learning applications, content-based filtering finds its use in various recommendation systems, such as suggesting movies, music, articles, or products to users based on their historical preferences or explicit feedback.
Using content based filtering in machine learning models can recommend new items that align with users' tastes, making the recommendation process more personalized and potentially increasing user satisfaction and engagement.

##KNN##

K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining, and intrusion detection.It can also handle both numerical and categorical data, making it a flexible choice for various types of datasets in classification and regression tasks. It is a non-parametric method that makes predictions based on the similarity of data points in a given dataset. K-NN is less sensitive to outliers compared to other algorithms.The applications of KNN are data preprocessing, pattern recognition, Recommendation Engines. 

##Why do we need a K-NN Algorithm?##
Suppose there are two categories, i.e., Category A and Category B, and we have a new data point x1, so this data point will lie in which of these categories. To solve this type of problem, we need a K-NN algorithm. With the help of K-NN, we can easily identify the category or class of a particular dataset. Consider the below diagram:

##How does K-NN work?##
The K-NN working can be explained on the basis of the below algorithm:

Step-1: Select the number K of the neighbors
Step-2: Calculate the Euclidean distance of K number of neighbors
Step-3: Take the K nearest neighbors as per the calculated Euclidean distance.
Step-4: Among these k neighbors, count the number of the data points in each category.
Step-5: Assign the new data points to that category for which the number of the neighbor is maximum.
Step-6: Our model is ready
##SciKit learn##

Scikit-learn is a powerful open-source library in Python used for machine learning tasks such as classification, regression, clustering, and more. It is built on top of other popular scientific computing libraries, such as NumPy, SciPy, and Matplotlib. It offers a wide range of tools for machine learning and statistical modeling, including various algorithms and utilities for data preprocessing, model selection, evaluation, and data visualization.
In practical terms, scikit-learn serves as a powerful toolbox for tasks such as data preprocessing, model training, and model evaluation. It includes utilities for handling data, implementing feature selection, and assessing model performance through cross-validation and grid search. 


##Pandas##

Pandas is an open-source Python library used for data manipulation and analysis. It provides powerful data structures and tools for working with structured data, primarily in the form of DataFrame objects. Pandas is widely utilized in machine learning for its ability to handle various data formats, such as CSV files, Excel sheets, SQL databases, and more. Its main data structure, the DataFrame, allows for easy indexing, slicing, cleaning, transforming, and aggregating data, making it an essential tool for data preprocessing in machine learning workflows.

It enables practitioners to load datasets, handle missing values, perform feature engineering by creating new features or transforming existing ones, encode categorical variables, and split data into training and testing sets. The ability to manipulate and prepare data efficiently using pandas is fundamental for ensuring that machine learning models receive high-quality input, leading to more accurate predictions or classifications.

##Numpy##

NumPy, short for Numerical Python, is a fundamental open-source library in Python for numerical computing. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays efficiently.In machine learning, NumPy is extensively used for data manipulation and preparation. It plays a central role in handling datasets, transforming features, and performing mathematical operations required during the preprocessing phase. Many machine learning libraries, including scikit-learn, TensorFlow, and PyTorch, leverage NumPy arrays as the underlying data structure. NumPy's efficient implementation of array operations significantly speeds up computations, making it an essential tool for implementing algorithms and models efficiently in machine learning workflows.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

##Use Case Diagram##

A use case diagram is used to represent the dynamic behavior of a system. It encapsulates the system's functionality by incorporating use cases, actors, and their relationships. It models the tasks, services, and functions required by a system/subsystem of an application. It depicts the high-level functionality of a system and also tells how the user handles a system.
It invokes persons, use cases, and several things that invoke the actors and elements accountable for the implementation of use case diagrams.
Following are the purposes of a use case diagram given below:

It gathers the system's needs.
It depicts the external view of the system.
It recognizes the internal as well as external factors that influence the system.
It represents the interaction between the actors.

##PERT CHART##

Project Evaluation and Review Technique (PERT) is a procedure through which activities of a project are represented in its appropriate sequence and timing. It is a scheduling technique used to schedule, organize and integrate tasks within a project. PERT is basically a mechanism for management planning and control which provides blueprint for a particular project. All of the primary elements or events of a project have been finally identified by the PERT. In this technique, a PERT Chart is made which represent a schedule for all the specified tasks in the project.

Components of pert chart:

1. Early Start (ES): Early Start refers to the earliest possible point in time when a particular task or activity can begin. It's determined by considering the immediate predecessors of the task—activities that must be completed before it can start.

2. Early Finish (EF): Early Finish denotes the earliest possible point in time when a task or activity can be completed. It is calculated by adding the task duration to its Early Start time.

3. Late Start (LS): Late Start represents the latest point in time when a task can start without delaying the project's overall completion. It considers the project's deadline and the time required for the task.

4. Late Finish (LF): Late Finish indicates the latest allowable completion time for a task without impacting the project's completion date. It is determined by subtracting the task duration from its Late Start time.

5. Slack (or Float): Slack or Float refers to the amount of time a task can be delayed without affecting subsequent tasks or the overall project completion time. It's calculated as the difference between the Late Start and Early Start times (or Late Finish and Early Finish times) for a task.

##ER Diagram##

The Entity Relational Model is a model for identifying entities to be represented in the database and representation of how those entities are related. The ER data model specifies enterprise schema that represents the overall logical structure of a database graphically. 

The Entity Relationship Diagram explains the relationship among the entities present in the database. ER models are used to model real-world objects like a person, a car, or a company and the relation between these real-world objects. In short, the ER Diagram is the structural format of the database. 

Components of ER diagram

1. Entity: An Entity may be an object with a physical existence – a particular person, car, house, or employee – or it may be an object with a conceptual existence – a company, a job, or a university course. 

	1. Strong Entity: A Strong Entity is a type of entity that has a key Attribute. Strong Entity does not depend on other Entity in the Schema. It has a primary key, that helps in identifying it uniquely, and it is represented by a rectangle. These are called Strong Entity Types.

	2. Weak Entity: An Entity type has a key attribute that uniquely identifies each entity in the entity set. But some entity type exists for which key attributes can’t be defined. These are called Weak Entity types. 

2. Attributes: Attributes are the properties that define the entity type. For example, Roll_No, Name, DOB, Age, Address, and Mobile_No are the attributes that define entity type Student. In ER diagram, the attribute is represented by an oval. 

	1. Key Attribute: The attribute which uniquely identifies each entity in the entity set is called the key attribute. For example, Roll_No will be unique for each student. In ER diagram, the key attribute is represented by an oval with underlying lines.


	2. Composite Attribute: An attribute composed of many other attributes is called a composite attribute. For example, the Address attribute of the student Entity type consists of Street, City, State, and Country. In ER diagram, the composite attribute is represented by an oval comprising of ovals. 


	3. Multivalued Attribute: An attribute consisting of more than one value for a given entity. For example, Phone_No (can be more than one for a given student). In ER diagram, a multivalued attribute is represented by a double oval. 


	4. Derived Attribute: An attribute that can be derived from other attributes of the entity type is known as a derived attribute. e.g.; Age (can be derived from DOB). In ER diagram, the derived attribute is represented by a dashed oval.  

Cardinality
The number of times an entity of an entity set participates in a relationship set is known as cardinality. Cardinality can be of different types: 

1. One-to-One: When each entity in each entity set can take part only once in the relationship, the cardinality is one-to-one. 

2. One-to-Many: In one-to-many mapping as well where each entity can be related to more than one relationship and the total number of tables that can be used in this is 2. 

3. Many-to-One: When entities in one entity set can take part only once in the relationship set and entities in other entity sets can take part more than once in the relationship set, cardinality is many to one. 

4. Many-to-Many: When entities in all entity sets can take part more than once in the relationship cardinality is many to many. Let us assume that a student can take more than one course and one course can be taken by many students. So the relationship will be many to many. 

##DFD##

DFD is the abbreviation for Data Flow Diagram. The flow of data of a system or a process is represented by DFD. It also gives insight into the inputs and outputs of each entity and the process itself. DFD does not have control flow and no loops or decision rules are present. Specific operations depending on the type of data can be explained by a flowchart. It is a graphical tool, useful for communicating with users ,managers and other personnel. it is useful for analyzing existing as well as proposed system.

Components of DFD:
 
The Data Flow Diagram has 4 components:

Process: Input to output transformation in a system takes place because of process function. The symbols of a process are rectangular with rounded corners, oval, rectangle or a circle. The process is named a short sentence, in one word or a phrase to express its essence.

Data Flow: Data flow describes the information transferring between different parts of the systems. The arrow symbol is the symbol of data flow. A relatable name should be given to the flow to determine the information which is being moved. Data flow also represents material along with information that is being moved. Material shifts are modeled in systems that are not merely informative. A given flow should only transfer a single type of information. The direction of flow is represented by the arrow which can also be bi-directional.

Warehouse: The data is stored in the warehouse for later use. Two horizontal lines represent the symbol of the store. The warehouse is simply not restricted to being a data file rather it can be anything like a folder with documents, an optical disc, a filing cabinet. The data warehouse can be viewed independent of its implementation. When the data flow from the warehouse it is considered as data reading and when data flows to the warehouse it is called data entry or data updating.

Terminator: The Terminator is an external entity that stands outside of the system and communicates with the system. It can be, for example, organizations like banks, groups of people like customers or different departments of the same organization, which is not a part of the model system and is an external entity. Modeled systems also communicate with terminator.

Levels of DFD: 

DFD uses hierarchy to maintain transparency thus multilevel DFD’s can be created. Levels of DFD are as follows:

0-level DFD: It represents the entire system as a single bubble and provides an overall picture of the system.
1-level DFD: It represents the main functions of the system and how they interact with each other. 
2-level DFD: It represents the processes within each function of the system and how they interact with each other.
3-level DFD: It represents the data flow within each process and how the data is transformed and stored.

##Iterative model##
The iterative model in software engineering is an approach where the project is broken down into smaller cycles or iterations. Each iteration goes through the entire software development life cycle (SDLC), encompassing planning, design, implementation, testing, and deployment. Here's a breakdown of the steps in the iterative model:

1. Planning: 
The initial step involved outlining the project's scope and aims. Our primary goal was to develop a career recommendation system catering specifically to secondary students. Defining this scope enabled us to identify crucial functionalities for this iteration, such as data collection methods, considering academic performance as a data source, determining educational levels, and specifying the machine learning algorithm, K-Nearest Neighbors, for personalized career recommendations.

2. Requirement Analysis: Gather and analyze user requirements specific to the current iteration. Focus on understanding what users need for the features or functionalities planned for this cycle. In this step, we understand the perspectives, aspirations, and academic concerns of a secondary student.Analyzing their needs enabled us to design a system that addressed their academic performance, interests, and potential career paths, making the project more user-specific and relevant.

3. Design: Building upon the gathered requirements, the design phase involved creating a system architecture tailored to 10th-grade students' needs. This encompassed designing a database architecture that integrated academic performance metrics, crafting user interaction pages that were intuitive and accessible, and developing a system that effectively processed and analyzed academic data to generate personalized career recommendations.  

4. Implementation/Coding: With the detailed design specifications in place, the project moved into the implementation phase. Here, the focus was on translating the design into functional components. This involved writing code for the identified features, including the recommendation model, user interaction elements like buttons and labels, and the underlying system that processed and utilized academic data to provide best possible career suggestions.

5. Testing: Perform testing activities such as unit testing, integration testing, and system testing. Ensure that the developed features meet the requirements and function correctly. In testing phase, manual testing was employed to identify and rectify errors and bugs encountered during this phase, ensuring a robust and reliable system.The aim was to ensure that every developed feature not only met the defined requirements but also functioned accurately and seamlessly. 

6. Evaluation/Review: Evaluate the results and identify areas for improvement and assess whether the iteration met its goals. In this step we evaluate the result of the system and find areas for imporvement to met the objective of project.

9. Iterations: Repeat the cycle for the next iteration. Incorporate changes based on feedback and update the plan to address new requirements or modifications.

##Activity Diagram##

A UML Activity diagram is a graphical representation used to model workflows and business processes within a system. It primarily focuses on the flow of activities or actions performed within a system, showcasing the sequence, conditions, and parallelism of these actions. Here are the main components of a UML Activity diagram:

1. Initial Node: Denotes the starting point of the activity diagram. It represents the initiation of the workflow.

2. Activity or Action: Represents a specific task or action within the system. It can be any operation, such as a calculation, decision-making process, or interaction.

3. Control Flow: Indicates the flow or sequence of activities. It's represented by arrows connecting different activities, showing the order in which actions occur.

4. Decision or Merge Node: Represents a branching point in the workflow where a decision is made or where different flows merge back together.

5. Fork and Join Nodes: Fork nodes split the flow into multiple concurrent flows, while join nodes synchronize these concurrent flows back into a single flow.

6. Final Node: Denotes the end of the activity diagram, representing the completion of the workflow.

7. Guard Condition: Represents the condition that determines which path to follow in a decision point. It's often depicted as text near the decision node or control flow arrow.

8.Swimlanes (Partition): Used to group activities performed by different actors or system components. They visually separate actions performed by different entities within the system.

9. Object Nodes: Represent objects or data consumed or produced during activities.

##Testing##

Software Testing is a method to assess the functionality of the software program. The process checks whether the actual software matches the expected requirements and ensures the software is bug-free. The purpose of software testing is to identify the errors, faults, or missing requirements in contrast to actual requirements. It mainly aims at measuring the specification, functionality, and performance of a software program or application. 

Types of software testing:

1. Manual Testing
2. Automation Testing

##Manual Testing##

Manual testing includes testing software manually, i.e., without using any automation tool or script. In this type, the tester takes over the role of an end-user and tests the software to identify any unexpected behavior or bug. There are different stages for manual testing such as unit testing, integration testing, system testing, and user acceptance testing. Testers use test plans, test cases, or test scenarios to test software to ensure the completeness of testing. Manual testing also includes exploratory testing, as testers explore the software to identify errors in it. 

Types of manual testing:

1. White Box
2. Black Box
3. Grey Box

##White Box##

White box testing techniques analyse the internal structures the used data structures, internal design, code structure, and the working of the software rather than just the functionality as in black box testing. It is also called glass box testing or clear box testing or structural testing. White Box Testing is also known as transparent testing or open box testing. 

White box testing is a software testing technique that involves testing the internal structure and workings of a software application. The tester has access to the source code and uses this knowledge to design test cases that can verify the correctness of the software at the code level.

White box testing is also known as structural testing or code-based testing, and it is used to test the software’s internal logic, flow, and structure. The tester creates test cases to examine the code paths and logic flows to ensure they meet the specified requirements.

##Input & Output Screen Design##

#---PyQt5--#

PyQt5 is cross-platform GUI toolkit, a set of python bindings for Qt v5. One can develop an interactive desktop application with so much ease because of the tools and simplicity provided by this library. A GUI application consists of Front-end and Back-end. PyQt5 has provided a tool called ‘QtDesigner’ to design the front-end by drag and drop method so that development can become faster and one can give more time on back-end stuff.

Here are some key aspects of PyQt5:

Cross-platform: Applications developed with PyQt5 can run on various operating systems like Windows, macOS, Linux, etc., without many modifications. This cross-platform capability is due to Qt's nature.

GUI Development: PyQt5 provides tools and classes to design and build graphical user interfaces using Qt Designer or programmatically within Python code. It includes widgets, layouts, dialogs, and more for creating interactive interfaces.

Event Handling: It allows developers to handle user interactions, events, signals, and slots effectively. This enables the creation of responsive applications by linking user actions to specific functions or methods.

Integration with Python: PyQt5 seamlessly integrates with Python, allowing developers to leverage the ease of Python programming while harnessing the power of the Qt framework.

Support for Multimedia: PyQt5 supports multimedia functionalities, such as playing audio and video files, thanks to Qt's multimedia modules.

Database Integration: It provides tools for integrating with databases, allowing developers to create applications that interact with various database systems


#--Components of pyqt5--#

PyQt5 offers a range of components and classes that enable developers to create Graphical User Interfaces (GUIs) in Python. Here are some key components commonly used in PyQt5 for GUI creation:

Widgets: PyQt5 provides a variety of widgets that form the building blocks of a GUI. These include:

QPushButton: Button widget for triggering actions.
QLabel: Display text or an image.
QLineEdit: Single-line text input field.
QTextEdit: Multiline text input/editing field.
QCheckBox and QRadioButton: Checkboxes and radio buttons for user selections.
QComboBox and QListWidget: Dropdown lists and list widgets for item selection.
QSlider and QSpinBox: Widgets for selecting numerical values.
Layout Management: PyQt5 includes layout classes that help in organizing and arranging widgets within a window or container. Common layout classes are:

QVBoxLayout and QHBoxLayout: Vertical and horizontal box layouts.
QGridLayout: Grid-based layout for arranging widgets in rows and columns.
QFormLayout: Organizes input fields and their labels in a structured form.
Dialogs: PyQt5 provides pre-built dialog windows for specific purposes, such as file dialogs, message boxes, input dialogs, and more. These include:

QFileDialog: Dialog for file selection.
QMessageBox: Dialog for displaying messages or alerts.
QInputDialog: Dialog for user input.
Custom Widgets: Developers can create custom widgets by subclassing existing PyQt5 widgets or by creating entirely new ones to suit specific application needs.

Events and Signals: PyQt5 uses a signals and slots mechanism to handle events and inter-widget communication. This allows actions in one widget to trigger specific functions or methods in another widget.

Graphics and Multimedia: PyQt5 includes classes for working with graphics and multimedia elements, allowing developers to incorporate images, videos, and graphics within their applications.

#--Qt Designer--#

Qt Designer is a visual design tool provided by the Qt framework for creating graphical user interfaces (GUIs). It is part of the Qt development environment and is commonly used in conjunction with PyQt, a set of Python bindings for the Qt framework. Here are the key features of Qt Designer:

1. Visual Design: Qt Designer allows developers to design GUIs visually by dragging and dropping UI components onto a form. This provides a WYSIWYG (What You See Is What You Get) environment, allowing designers and developers to see the appearance of the UI as they design it.

2. Widget Box: Qt Designer provides a widget box that contains a variety of standard UI components (widgets) such as buttons, labels, text fields, and more. Developers can easily select and place these widgets on the form.

3. Layout Management: It supports the design of complex layouts through various layout managers, including vertical and horizontal box layouts, grid layouts, and form layouts. This helps in arranging and organizing widgets within a window.

4. Property Editor: Developers can use the property editor to customize the properties of UI components, such as their size, position, text, and appearance. This allows for fine-tuning the visual aspects of the GUI.

5. Signal and Slot Editing: Qt Designer provides an interface for connecting signals and slots, which facilitates event handling and interaction between different UI components. This is a fundamental aspect of Qt's programming model.

6. Integration with Code Editors: While Qt Designer is primarily a visual tool, it seamlessly integrates with code editors. Developers can easily switch between the visual design in Qt Designer and the corresponding code in their preferred integrated development environment (IDE).

7. Custom Widget Integration: Qt Designer allows developers to integrate custom widgets into the design process. This is particularly useful when developers have created their own specialized UI components.

8. Preview Mode: Developers can preview the appearance and behavior of the GUI directly within Qt Designer before generating the code. This helps in identifying any design issues before deploying the application.

9. UI File Generation: Qt Designer saves the designed UI in a .ui file format, which is an XML-based file. This file can be loaded and used by the application code, enabling the separation of UI design and logic.
